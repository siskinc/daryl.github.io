<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Redis on Daryl&#39;s Blog</title>
    <link>https://siskinc.github.io/categories/redis/</link>
    <description>Recent content in Redis on Daryl&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 12 Sep 2020 16:45:46 +0000</lastBuildDate><atom:link href="https://siskinc.github.io/categories/redis/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>幂次定律在Redis中的应用</title>
      <link>https://siskinc.github.io/post/%E5%B9%82%E6%AC%A1%E5%AE%9A%E5%BE%8B%E5%9C%A8redis%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/</link>
      <pubDate>Sat, 12 Sep 2020 16:45:46 +0000</pubDate>
      
      <guid>https://siskinc.github.io/post/%E5%B9%82%E6%AC%A1%E5%AE%9A%E5%BE%8B%E5%9C%A8redis%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/</guid>
      <description>幂次定律  如果某件事的发生频率和它的某个属性成幂关系，那么这个频率就可以称之为符合幂次定律。幂次定律的表现是少数几个事件的发生频率占了整个发生频率的大部分， 而其余的大多数事件只占整个发生频率的一个小部分。幂次定律
 Redis中的应用  在Redis中的跳表内容中有一个zslRandomLevel函数，返回一个随机的层级
 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  /* Returns a random level for the new skiplist node we are going to create. * The return value of this function is between 1 and ZSKIPLIST_MAXLEVEL * (both inclusive), with a powerlaw-alike distribution where higher * levels are less likely to be returned.</description>
    </item>
    
    <item>
      <title>redis lua script注意点</title>
      <link>https://siskinc.github.io/post/redis_lua_script%E6%B3%A8%E6%84%8F%E7%82%B9/</link>
      <pubDate>Sun, 16 Aug 2020 22:26:29 +0000</pubDate>
      
      <guid>https://siskinc.github.io/post/redis_lua_script%E6%B3%A8%E6%84%8F%E7%82%B9/</guid>
      <description>脚本死循环 Redis 的指令执行是个单线程，这个单线程还要执行来自客户端的 lua 脚本。如果 lua 脚本中来一个死循环，在脚本没有对 Redis 的内部数据状态进行修改时，可以使用script kill指令用于动态杀死一个执行时间超时的 lua 脚本。因为 Redis 不允许 script kill 破坏脚本执行的原子性。比如脚本内部使用了 redis.call(&amp;ldquo;set&amp;rdquo;, key, value) 修改了内部的数据，那么 script kill 执行时服务器会返回错误。
Script Kill 的原理 lua 脚本引擎功能太强大了，它提供了各式各样的钩子函数，它允许在内部虚拟机执行指令时运行钩子代码。比如每执行 N 条指令执行一次某个钩子函数，Redis 正是使用了这个钩子函数。

1 2 3 4 5 6 7 8 9 10 11 12 13  void evalGenericCommand(client *c, int evalsha) { ... // lua引擎每执行10w条指令，执行一次钩子函数 luaMaskCountHook  lua_sethook(lua,luaMaskCountHook,LUA_MASKCOUNT,100000); ... }   </description>
    </item>
    
    <item>
      <title>Redis源码阅读之quicklist</title>
      <link>https://siskinc.github.io/post/redis%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E4%B9%8Bquicklist/</link>
      <pubDate>Thu, 21 May 2020 23:37:05 +0000</pubDate>
      
      <guid>https://siskinc.github.io/post/redis%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E4%B9%8Bquicklist/</guid>
      <description>数据结构 quicklistNode 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41  /* quicklistNode is a 32 byte struct describing a ziplist for a quicklist. * We use bit fields keep the quicklistNode at 32 bytes. * count: 16 bits, max 65536 (max zl bytes is 65k, so max count actually &amp;lt; 32k).</description>
    </item>
    
    <item>
      <title>Redis字典扩张算法</title>
      <link>https://siskinc.github.io/post/redis%E5%AD%97%E5%85%B8%E6%89%A9%E5%BC%A0%E7%AE%97%E6%B3%95/</link>
      <pubDate>Sat, 16 May 2020 00:05:19 +0000</pubDate>
      
      <guid>https://siskinc.github.io/post/redis%E5%AD%97%E5%85%B8%E6%89%A9%E5%BC%A0%E7%AE%97%E6%B3%95/</guid>
      <description>源码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  /* This is the initial size of every hash table */ #define DICT_HT_INITIAL_SIZE 4  /* Our hash table capability is a power of two */ static unsigned long _dictNextPower(unsigned long size) { unsigned long i = DICT_HT_INITIAL_SIZE; if (size &amp;gt;= LONG_MAX) return LONG_MAX + 1LU; while(1) { if (i &amp;gt;= size) return i; i *= 2; } }   结论  Redis的dict会从4开始扩张，最大到达LONG_MAX + 1LU</description>
    </item>
    
    <item>
      <title>Redis源码阅读之动态字符串</title>
      <link>https://siskinc.github.io/post/redis%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E4%B9%8B%E5%8A%A8%E6%80%81%E5%AD%97%E7%AC%A6%E4%B8%B2/</link>
      <pubDate>Sun, 10 May 2020 11:07:16 +0000</pubDate>
      
      <guid>https://siskinc.github.io/post/redis%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E4%B9%8B%E5%8A%A8%E6%80%81%E5%AD%97%E7%AC%A6%E4%B8%B2/</guid>
      <description>数据结构 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65  typedef char *sds; /* Note: sdshdr5 is never used, we just access the flags byte directly.</description>
    </item>
    
    <item>
      <title>Redis源码阅读之内存分配</title>
      <link>https://siskinc.github.io/post/redis%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E4%B9%8B%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D/</link>
      <pubDate>Wed, 22 Apr 2020 23:01:09 +0000</pubDate>
      
      <guid>https://siskinc.github.io/post/redis%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E4%B9%8B%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D/</guid>
      <description>zmalloc是什么  zmalloc是redis内存分配的基本操作，相当于包了一层malloc的操作，分配出来的内存不只是裸露的
 API 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  void *zmalloc(size_t size); void *zcalloc(size_t size); void *zrealloc(void *ptr, size_t size); void zfree(void *ptr); char *zstrdup(const char *s); size_t zmalloc_used_memory(void); void zmalloc_set_oom_handler(void (*oom_handler)(size_t)); size_t zmalloc_get_rss(void); int zmalloc_get_allocator_info(size_t *allocated, size_t *active, size_t *resident); void set_jemalloc_bg_thread(int enable); int jemalloc_purge(); size_t zmalloc_get_private_dirty(long pid); size_t zmalloc_get_smap_bytes_by_field(char *field, long pid); size_t zmalloc_get_memory_size(void); void zlibc_free(void *ptr);   内存分配zmalloc，zcalloc 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  void *zmalloc(size_t size) { void *ptr = malloc(size+PREFIX_SIZE); if (!</description>
    </item>
    
    <item>
      <title>Redis源码阅读之字典（二）——Rehash</title>
      <link>https://siskinc.github.io/post/redis%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E4%B9%8B%E5%AD%97%E5%85%B8%E4%BA%8Crehash/</link>
      <pubDate>Tue, 21 Apr 2020 23:58:01 +0000</pubDate>
      
      <guid>https://siskinc.github.io/post/redis%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E4%B9%8B%E5%AD%97%E5%85%B8%E4%BA%8Crehash/</guid>
      <description>历史文章 Redis源码阅读之字典（一）
Redis Rehash是什么？  在我们日常使用redis的过程中，随着key不断的增加，dict的size也在不断的增加，当dict.used == dict.size或者used*100/size &amp;lt; HASHTABLE_MIN_FILL,HASHTABLE_MIN_FILL一般为10，也就是说，要么容量不够，要么容量使用率小于10%了，就会调用dictExpand进行重新分配内存，这个时候就会触发rehash了。但是rehash不行一次性就操作完成了，试想一下，如果一个dict里面含有数百万的key，rehash一次可能会很久，就可能造成服务假死的情况。所以rehashing是一个长时间的过程，每一次可能只进行几个key的迁移。
 哪些操作会触发rehashing的step dictRehashMilliseconds  redis server的定时任务会去执行dictRehashMilliseconds，但是都是传入的ms==1，主要是rehashing一下redis的dict和expired相关的键
 dictAddRaw  在给dict增加key的时候，新增的key会直接放入dict.ht[1]中
 dictGenericDelete  删除key时
 dictFind  查找key
 dictGetRandomKey 和 dictGetSomeKeys  获取随机key
 dictScan  遍历dict
 每次rehash的过程 源码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107  /* Performs N steps of incremental rehashing.</description>
    </item>
    
    <item>
      <title>Redis源码阅读-dict</title>
      <link>https://siskinc.github.io/post/redis%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB-dict/</link>
      <pubDate>Tue, 21 Apr 2020 23:23:41 +0000</pubDate>
      
      <guid>https://siskinc.github.io/post/redis%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB-dict/</guid>
      <description>数据结构 字典的基本单元——dictEntry 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  typedef struct dictEntry { void *key; union { void *val; uint64_t u64; int64_t s64; double d; } v; struct dictEntry *next; } dictEntry;   dictEntry是Redis中的哈希表数据接口的基本单元，有一个指向key的指针，还有一个联合体v，代表的是字典的值，它可以是一个数字（浮点或者有符号整型或者无符号整型），还有一个next字段指向下一个dictEntry的指针。说明了一个问题，dictEntry其实是一个链表节点。
哈希表——dictht 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  /* This is our hash table structure.</description>
    </item>
    
    <item>
      <title>Redis源码阅读之字典（一）</title>
      <link>https://siskinc.github.io/post/redis%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E4%B9%8B%E5%AD%97%E5%85%B8%E4%B8%80/</link>
      <pubDate>Tue, 21 Apr 2020 23:23:41 +0000</pubDate>
      
      <guid>https://siskinc.github.io/post/redis%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E4%B9%8B%E5%AD%97%E5%85%B8%E4%B8%80/</guid>
      <description>数据结构 字典的基本单元——dictEntry 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  typedef struct dictEntry { void *key; union { void *val; uint64_t u64; int64_t s64; double d; } v; struct dictEntry *next; } dictEntry;   dictEntry是Redis中的哈希表数据接口的基本单元，有一个指向key的指针，还有一个联合体v，代表的是字典的值，它可以是一个数字（浮点或者有符号整型或者无符号整型），还有一个next字段指向下一个dictEntry的指针。说明了一个问题，dictEntry其实是一个链表节点。
哈希表——dictht 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  /* This is our hash table structure.</description>
    </item>
    
    <item>
      <title>redis源码解读--动态字符串SDSHDR</title>
      <link>https://siskinc.github.io/post/redis%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-%E5%8A%A8%E6%80%81%E5%AD%97%E7%AC%A6%E4%B8%B2sdshdr/</link>
      <pubDate>Thu, 25 Jul 2019 16:54:31 +0000</pubDate>
      
      <guid>https://siskinc.github.io/post/redis%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-%E5%8A%A8%E6%80%81%E5%AD%97%E7%AC%A6%E4%B8%B2sdshdr/</guid>
      <description>阅读源码: sds.h sds.c
SDSHDR 全称 Simple Dynamic Strings Header
sds  char *的别名
 1 2 3  typedef char *sds;   sdshdr  sdshdr有好几个类别，它们分别是：sdshdr5，sdshdr8，sdshdr16，sdshdr32，sdshdr64，其中sdshdr5是不使用的
 源码如下：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61  /* Note: sdshdr5 is never used, we just access the flags byte directly.</description>
    </item>
    
    <item>
      <title>redis源码解读--内存分配zmalloc</title>
      <link>https://siskinc.github.io/post/redis%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-%E5%86%85%E5%AD%98%E5%88%86%E9%85%8Dzmalloc/</link>
      <pubDate>Thu, 25 Jul 2019 16:52:10 +0000</pubDate>
      
      <guid>https://siskinc.github.io/post/redis%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-%E5%86%85%E5%AD%98%E5%88%86%E9%85%8Dzmalloc/</guid>
      <description>主要函数   void *zmalloc(size_t size);
  void *zcalloc(size_t size);
  void *zrealloc(void *ptr, size_t size);
  void zfree(void *ptr);
  char *zstrdup(const char *s);
  size_t zmalloc_used_memory(void);
  void zmalloc_set_oom_handler(void (*oom_handler)(size_t));
  size_t zmalloc_get_rss(void);
  int zmalloc_get_allocator_info(size_t *allocated, size_t *active, size_t *resident);
  size_t zmalloc_get_private_dirty(long pid);
  size_t zmalloc_get_smap_bytes_by_field(char *field, long pid);
  size_t zmalloc_get_memory_size(void);
  void zlibc_free(void *ptr);</description>
    </item>
    
    <item>
      <title>redis_mongodb持久化的方式</title>
      <link>https://siskinc.github.io/post/redis-mongodb%E6%8C%81%E4%B9%85%E5%8C%96%E7%9A%84%E6%96%B9%E5%BC%8F/</link>
      <pubDate>Thu, 25 Jul 2019 04:36:53 +0000</pubDate>
      
      <guid>https://siskinc.github.io/post/redis-mongodb%E6%8C%81%E4%B9%85%E5%8C%96%E7%9A%84%E6%96%B9%E5%BC%8F/</guid>
      <description>redis持久化方式(两种) RDB持久化 redis提供了RDB持久化的功能，这个功能可以将redis在内存中的的状态保存到硬盘中，相当于snapshot，它可以手动执行，也可以再redis.conf中配置，定期执行。
相关配置   databases
配置db文件的数目，可以用select dbid 指令为每个连接指定后续持久化时的db文件，新连接默认均使用db 0
  save
SNAPSHOTTING的持久化方式有多种save策略可供选择，而且支持混用，例如：
save 900 1
save 300 100
save 60 10000
上述配置的效果是：snapshotting会在3个条件中的任何一个满足时被触发：
  900s内至少1个key有变化；
  300s内至少100个key有变化；
  60s内至少有10000个key有变化
  save条件被触发时，Redis通过fork子进程，由子进程在后台实现异步dump磁盘。根据fork的写时复制策略，若持久化过程中出现很多写入请求，在最坏的情况下，需要的内存是当前数据集所占内存的2倍。
备注1：上述配置的3个触发条件其实是逐次加强的，哪个条件先满足就先触发那个save策略。
备注2：如果业务不需要持久化或不需要RDB方式的持久化，可以通过注释掉save配置项来实现
  stop-writes-on-bgsave-error
指定Redis在后台dump磁盘出错时的行为，默认为yes，表示若后台dump出错，则RedisServer拒绝新的写入请求，通过这种方式来引起用户警觉，避免因用户未发现异常而引起更大的事故。
  rdbcompression
RDB文件是否压缩存储，若为yes，会在压缩时消耗一点CPU，但省磁盘空间。
  rdbchecksum
RDB文件是否需要CRC64校验, 若为yes,会在生成RDB文件后计算其CRC64并将结果追加至文件尾，同样，Redis启动Load RDB时，也会先计算该文件的CRC64并与dump时的计算结果对比。
   好处：可以严格保证RDB的完整性及安全性
 代价：会在dump或load时损失10%的性能。如果要最大化Redis的性能，这个配置项应该用no关掉
 dbfilename
指定RDB文件名，默认为dump.rdb
  dir
指定RDB文件存放目录的路径，若包含多级路径，则相关父路径需事先mkdir出来，否则启动失败。
  AOF持久化 AOF持久化（Append-Only-File），与RDB持久化不同，AOF持久化是通过保存Redis服务器锁执行的写状态来记录数据库的，即commandlog。</description>
    </item>
    
  </channel>
</rss>
